{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Convert file data"
      ],
      "metadata": {
        "id": "qFoF3V36RaGY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert Format\n",
        "\n",
        "If file data (train/dev/test) have format like ViQuAD or SQuAD. You need to change the format of the data file so that the code can load and run."
      ],
      "metadata": {
        "id": "GQKmbQRSbqJe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fn8DKuKlBaxi"
      },
      "outputs": [],
      "source": [
        "# Path to train/dev/test file of ViQuAD\n",
        "path_train = \"path-to-train-file\" \n",
        "# Ex: path-to-train-file is /content/Train.json\n",
        "path_dev = \"path-to-dev-file\"\n",
        "path_test = \"path-to-test-file\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 convert_format.py path_train \"path-to-save-new-train-file.json\" 2"
      ],
      "metadata": {
        "id": "JMpuW8xdB1xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "where path_train is the data file with old format, \"path-to-save-new-train-file.json\" is the data file created after the conversion is complete and the last number is the version of the data (2 is for unanswerable question and answerable question, 1 is for answerable question only)"
      ],
      "metadata": {
        "id": "tiCMpc93TPaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 convert_format.py path_dev \"path-to-save-new-dev-file.json\" 2"
      ],
      "metadata": {
        "id": "gno5NKGIChKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 convert_format.py path_test \"path-to-save-new-test-file.json\" 2"
      ],
      "metadata": {
        "id": "72duKRYqChrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert Question Word \n",
        "\n",
        "Apply rule convert question word for dataset\n",
        "\n",
        "You can save the data file after converting the question word as another file for later use. But due to the restriction of generating too many files, I overwritten the old file."
      ],
      "metadata": {
        "id": "mYDK0rcUbs5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python apply_question_word.py \"path-to-save-new-train-file.json\" \"path-to-save-new-train-file.json\""
      ],
      "metadata": {
        "id": "fyu8boInbyxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Where, the first parameter is the name of the data file to be converted, the second parameter is the file to be saved after conversion"
      ],
      "metadata": {
        "id": "lQbivJgbcQu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python apply_question_word.py \"path-to-save-new-dev-file.json\" \"path-to-save-new-test-file.json\""
      ],
      "metadata": {
        "id": "FAsMWQ3zb68k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python apply_question_word.py \"path-to-save-new-test-file.json\" \"path-to-save-new-test-file.json\""
      ],
      "metadata": {
        "id": "iMdnP-EAb7Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Training MRC4MRC"
      ],
      "metadata": {
        "id": "CrCDzGTCTDvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MRC4MRC has two machine reading comprehension, so we need training two model including: MRC1 and MRC2"
      ],
      "metadata": {
        "id": "Ro_ilhj4UD-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training MRC1"
      ],
      "metadata": {
        "id": "JS2jqIR1T99O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 run_qa.py \\\n",
        "  --model_name_or_path xlm-roberta-large \\\n",
        "  --train_file \"path-to-save-new-train-file.json\" \\\n",
        "  --validation_file \"path-to-save-new-dev-file.json\" \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --per_device_train_batch_size 4 \\\n",
        "  --learning_rate 2e-5 \\\n",
        "  --num_train_epochs 2 \\\n",
        "  --max_seq_length 384 \\\n",
        "  --max_answer_length 128 \\\n",
        "  --doc_stride 128 \\\n",
        "  --save_steps 1000 \\\n",
        "  --overwrite_output_dir \\\n",
        "  --version_2_with_negative True \\\n",
        "  --output_dir  './MRC1' #path-to-save-model-mrc1"
      ],
      "metadata": {
        "id": "nv_MTPyDCn0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training MRC2"
      ],
      "metadata": {
        "id": "jt8ncQgUUBgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 run_qa.py \\\n",
        "  --model_name_or_path xlm-roberta-large \\\n",
        "  --train_file \"path-to-save-new-train-file.json\" \\\n",
        "  --validation_file \"path-to-save-new-dev-file.json\" \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --per_device_train_batch_size 4 \\\n",
        "  --learning_rate 2e-5 \\\n",
        "  --num_train_epochs 2 \\\n",
        "  --max_seq_length 384 \\\n",
        "  --max_answer_length 128 \\\n",
        "  --doc_stride 128 \\\n",
        "  --save_steps 1000 \\\n",
        "  --overwrite_output_dir \\\n",
        "  --output_dir  './MRC2' #path-to-save-model-mrc2"
      ],
      "metadata": {
        "id": "Ww2P9TceC9dQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Evaluate and Predictions"
      ],
      "metadata": {
        "id": "SV3wkuY7U1_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate in MRC1"
      ],
      "metadata": {
        "id": "rH5WxkxFVR2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_qa.py \\\n",
        "  --model_name_or_path \"./MRC1\" \\\n",
        "  --test_file \"path-to-save-new-test-file.json\" \\\n",
        "  --do_predict \\\n",
        "  --per_device_train_batch_size 4 \\\n",
        "  --learning_rate 2e-5 \\\n",
        "  --num_train_epochs 2 \\\n",
        "  --max_seq_length 384 \\\n",
        "  --max_answer_length 128 \\\n",
        "  --doc_stride 128 \\\n",
        "  --save_steps 1000 \\\n",
        "  --overwrite_output_dir \\\n",
        "  --version_2_with_negative True \\\n",
        "  --output_dir \"dir-to-save-result-mrc1\". # You should save it in ./MRC1 to easy evaluate"
      ],
      "metadata": {
        "id": "wJc_hQOjDC4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate in MRC2"
      ],
      "metadata": {
        "id": "u7oVqFiMVUBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_qa.py \\\n",
        "  --model_name_or_path \"./MRC1\" \\\n",
        "  --test_file \"path-to-save-new-test-file.json\" \\\n",
        "  --do_predict \\\n",
        "  --per_device_train_batch_size 4 \\\n",
        "  --learning_rate 2e-5 \\\n",
        "  --num_train_epochs 2 \\\n",
        "  --max_seq_length 384 \\\n",
        "  --max_answer_length 128 \\\n",
        "  --doc_stride 128 \\\n",
        "  --save_steps 1000 \\\n",
        "  --overwrite_output_dir \\\n",
        "  --output_dir \"dir-to-save-result-mrc2\". # You should save it in ./MRC2 to easy evaluate"
      ],
      "metadata": {
        "id": "n9ta1DtUDjXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine result of MRC1 and MRC2"
      ],
      "metadata": {
        "id": "tml5M-o5VXyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 combine_prediction.py \"path-to-save-new-test-file.json\" \"dir-to-save-result-mrc1\" \"dir-to-save-result-mrc2\""
      ],
      "metadata": {
        "id": "ejoD6_PYElKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Compute Metrics F1-score and EM"
      ],
      "metadata": {
        "id": "c-c9eYqVVcd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install datasets"
      ],
      "metadata": {
        "id": "2gCWbLakLZu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datasets import load_metric\n",
        "metric = load_metric(\"squad_v2\")\n",
        "\n",
        "# Prediction\n",
        "# MRC4MRC_prediction.json is generated after running file combine_prediction.py\n",
        "with open(\"MRC4MRC_prediction.json\") as f:\n",
        "  final_predictions = json.load(f)\n",
        "formatted_predictions = [{\"id\": k, \"prediction_text\": v, \"no_answer_probability\": 0.0} for k, v in final_predictions.items()]\n",
        "\n",
        "# Gold label\n",
        "# path-to-save-new-test-file.json is created in step 1\n",
        "with open(\"path-to-save-new-test-file.json\") as f:\n",
        "  data_test = json.load(f)[\"data\"]\n",
        "references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in data_test]\n",
        "\n",
        "metric.compute(predictions=formatted_predictions, references=references)"
      ],
      "metadata": {
        "id": "DI1vNzAZLcUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T_dN04NEOdd0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}